---
title: "2024.09 blog review"
date: 2024-08-31T17:40:57+08:00
draft: false
toc: false
description: blog review
tags: 
  - blog
---

# NetWork

## 工业级大规模RDMA技术杂谈 & 《RDMA杂谈》专栏索引
[《RDMA杂谈》专栏索引](https://zhuanlan.zhihu.com/p/164908617)
[工业级大规模RDMA技术杂谈](https://zhuanlan.zhihu.com/p/510323418)

非常好的资料，扫盲RDMA用

## Deploying User-space TCP at Cloud Scale with LUNA

[链接](https://www.usenix.org/conference/atc23/presentation/zhu-lingjun)
需要用户态tcp的原因
1. 存储集群内可以rdma，但计算集群和存储集群之间可能跨pod，RDMA默认流控为PFC，跨Pod通信，存在PFC风暴和死锁等隐患;且计算节点硬件可能不支持rdma
2. 内核tcp性能不达标（一次4KB的RTT大概需要50us，而EBS的SLO就是100us），不够scale，存在datacenter tax
3. 方便做RTC

Luna的几个特点
1. 作为一个libary，集成到用户进程中
2. share nothing，利用网卡多队列技术，按照核心划分流量。没有work steal这种复杂的机制。
3. 兼容内核TCP
4. 线程模型上，Run to Completion
5. 内存模型上，构建用户态内存分配器，实现全路径zero copy

Luna 4KB的RTT latency大概在20us（kernel 为50us）

## From Luna to Solar: The Evolutions of the Compute-to-Storage Networks in Alibaba Cloud
[链接](https://zhuanlan.zhihu.com/p/648322713)
Luna相比于Kernel，能节省CPU，但随着硬件的发展，它对CPU的 消耗还是不可忽视，比如说Luna需要吃掉4个core来跑满200Gbps网卡（Kernel需要12个）；再加上计算节点上的存储Agent（做路由，加解密，CRC等），会消耗客户机的不少CPU。
Solar就将协议栈和Agent Offload到了FPGA中（相当于DPU）。基于RoceV2,传出层协议为UDP，拥塞控制算法为HPCC

# Storage
## S3: A Scalable In-memory Skip-List Index for Key-Value Store
[链接](https://www.vldb.org/pvldb/vol12/p2183-zhang.pdf)

1. Skip-List顶层节点称为Guard Entry，限制其的总大小，使其能被L2 Cache住。
2. 其余节点称为Data Entry，一个Data Entry可以容纳若干kv，Data Entry内key无序，Data Entry间有序i（看论文的图就明白
3. Guard Entry按照线程来shard写入，第i个Guard Entry和i+1个Guard Entry之间的数据更新由一个线程负责